{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import string\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from Constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['csharp', 'java', 'javascript', 'python']\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(\"../outputs\", \"stackoveflow_query\")\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "print(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"how to create an infinite loop with apply_async? i havea pool of processes with apply_async in which the different processes take different times to provide output. once one process is finished i do some calculations with their output. after i want to launch another process. in this way i want to create an infinite loop which launches processes, reads the output of the recently finished process, does some calculations and relaunches another process...so far i have been able to do what i want except that the main process gets stuck in the get() function. this because i don't know which process terminated and hence which entry of results i should do get()...some attempt code:..import multiprocessing as mp.import numpy as np.from time import sleep...def squared(x,y):.    result = np.array((x,x)).    if x%2 == 0:.    sleep(2) .return result.....if __name__ == \"\"__main__\"\":..    pool = mp.pool() ..    pool_r = [].    for i in xrange(0,8):.        pool_r.append(pool.apply_async(squared, (i,i)))..    count_results = 0..    for j in xrange(0,10):.        result = pool_r[count_results].get().        print result.        count_results += 1.        pool_r.append(pool.apply_async(squared, (j,j)))..    pool.close().    pool.join()...and the output is: .    [0 0].    [1 1].    [2 2].    [3 3].    [4 4].    [5 5].    [6 6].    [7 7].    [0 0].    [1 1]..instead of the odd numbers first and then the even ones (since these ones have a sleep)...any suggestions?....thank you very much for your fast reply abarnert. ..in reality i want to keep an infinite loop after the processes are completed (i need their results to be able to enter the loop). ..q1 - if i create a pool with 30 works can i submit more than 30 processes? will the computer wait for one to finish to put another to work? ..q2 - in your code there is a callback function. however, the code that the i need to run when one worker finishes has to be in the main process since i have to update variables which will be sent to the new processes that i create...q3 - the code that the main process does takes, let say 10% of the time that the processes need to realize their tasks. so is it a good approach to have the main process to realize some calculations and then launch new processes? ..q4 - right now if i ctrl+c the code only terminates when all the processes are over. what can i do to be able to terminate the code as soon as i do ctrl+c? and finally, after my comment do you think futures is still the way to go?..some pseudo-code for what i need:..launch several processes.wait for the results..launch several processes..while true:..    get results from a recently finished process..    do some calculations..    launch two more processes..    # some ending condition\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.path.join(train_dir, 'python/1.txt')\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())\n",
    "    \n",
    "# modify to be able to take more than one and randomly and also one randomly from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest query: 2256 words\n"
     ]
    }
   ],
   "source": [
    "def longest_query(data_paths):\n",
    "    max_length = 0\n",
    "    for path in data_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = ''.join([character for character in text if character not in string.punctuation])\n",
    "            text = re.sub('<[^>]+>+', '', text)\n",
    "            corpus = [word for word in text.split()]\n",
    "        if len(corpus) > max_length:\n",
    "            max_length = len(corpus)\n",
    "    return max_length\n",
    "\n",
    "file_paths = []\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"csharp\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"java\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"javascript\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"python\", \"*.txt\")))\n",
    "\n",
    "longest_query = longest_query(file_paths)\n",
    "print(f\"Longest query: {longest_query} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average query length: 123.774375 words\n"
     ]
    }
   ],
   "source": [
    "def avg_query_length(data_paths):\n",
    "    query_length = []\n",
    "    for path in data_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = ''.join([character for character in text if character not in string.punctuation])\n",
    "            #text = re.sub('<[^>]+>+', '', text)\n",
    "            corpus = [word for word in text.split()]\n",
    "        query_length.append(len(corpus))\n",
    "    return sum(query_length) / len(query_length)\n",
    "\n",
    "file_paths = []\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"csharp\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"java\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"javascript\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"python\", \"*.txt\")))\n",
    "\n",
    "average_query_length = avg_query_length(file_paths)\n",
    "print(f\"Average query length: {average_query_length} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = int(longest_query)\n",
    "NUM_WORDS = -1\n",
    "VALIDATION_SPLIT = 0.25\n",
    "EMBED_DIM = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(file_paths, most_common = None):\n",
    "    corpus = []\n",
    "    for path in file_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = re.sub('<[^>]+>+', '', text)\n",
    "            corpus.extend([word for word in text.split()])\n",
    "    word_count = Counter(corpus)\n",
    "    common_words = word_count.most_common(n = most_common)\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_int(input_words, num_words):\n",
    "    if num_words > -1:\n",
    "        int_mapping = {w:i + 1 for i, (w, c) in enumerate(input_words) if i <= num_words - 1}\n",
    "    else:\n",
    "        int_mapping = {w:i + 1 for i, (w, c) in enumerate(input_words)}\n",
    "    return int_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationBlock(Dataset):\n",
    "    def __init__(self, file_paths, common_words, int_mapping, max_len):\n",
    "        self.word_frequency = word_frequency\n",
    "        self.int_mapping = int_mapping\n",
    "        self.file_paths = file_paths\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def text_standardiser(self, input_text):\n",
    "        text = input_text.lower()\n",
    "        text = re.sub('<[^>]+>+', '', text)\n",
    "        text = ''.join([character for character in text if character not in string.punctuation])\n",
    "        return text\n",
    "    \n",
    "    def get_word_vectors(self, int_mapping, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = self.text_standardiser(text)\n",
    "            corpus = [word for word in text.split()]\n",
    "        int_vector = [int_mapping[word] for word in text.split() if word in int_mapping]\n",
    "        return int_vector\n",
    "    \n",
    "    def pad_features(self, int_vector, max_len):\n",
    "        features = np.zeros((1, max_len), dtype = int)\n",
    "        if len(int_vector) <=  max_len:\n",
    "            zeros = list(np.zeros(max_len - len(int_vector)))\n",
    "            new = zeros + int_vector\n",
    "        else:\n",
    "            new = int_vector[: max_len]\n",
    "        features = np.array(new)\n",
    "        return features\n",
    "    \n",
    "    def encode_labels(self, file_path):\n",
    "        file_path = pathlib.Path(file_path)\n",
    "        class_label = str(file_path).split(os.path.sep)[-2]\n",
    "        if class_label == \"csharp\":\n",
    "            int_label = 0\n",
    "        elif class_label == \"java\":\n",
    "            int_label = 1\n",
    "        elif class_label == \"javascript\":\n",
    "            int_label = 2\n",
    "        elif class_label == \"python\":\n",
    "            int_label = 3\n",
    "        return int_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.file_paths[index]\n",
    "        int_vector = self.get_word_vectors(self.int_mapping, file_path)\n",
    "        padded_features = self.pad_features(int_vector, self.max_len)\n",
    "        label = self.encode_labels(file_path)\n",
    "        return {\n",
    "            \"text\": torch.tensor(padded_features, dtype = torch.int32),\n",
    "            \"label\": torch.tensor(label, dtype = torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"csharp\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"java\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"javascript\", \"*.txt\")))\n",
    "file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"python\", \"*.txt\")))\n",
    "\n",
    "test_file_paths = []\n",
    "test_file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"csharp\", \"*.txt\")))\n",
    "test_file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"java\", \"*.txt\")))\n",
    "test_file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"javascript\", \"*.txt\")))\n",
    "test_file_paths.extend(glob.glob(os.path.join(dataset_dir, \"train\", \"python\", \"*.txt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency = word_frequency(file_paths)\n",
    "int_mapping = word_to_int(word_frequency, num_words = NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 6000\n",
      "Testing samples: 8000\n",
      "Validation samples: 2000\n"
     ]
    }
   ],
   "source": [
    "dataset = ClassificationBlock(file_paths, word_frequency, int_mapping, MAX_LEN)\n",
    "dataset_size = len(dataset)\n",
    "validation_size = int(VALIDATION_SPLIT * dataset_size)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "train_set = Subset(dataset, indices[:-validation_size])\n",
    "validation_set = Subset(dataset, indices[-validation_size:])\n",
    "test_set = ClassificationBlock(test_file_paths, word_frequency, int_mapping, MAX_LEN)\n",
    "print(f\"Training samples: {len(train_set)}\")\n",
    "print(f\"Testing samples: {len(test_set)}\")\n",
    "print(f\"Validation samples: {len(validation_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': tensor([  0,   0,   0,  ...,   4, 380,  15], dtype=torch.int32), 'label': tensor(0)}\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " how add a list of elements into a list without reference i cannot find an answer because it seems too much specific so heres my issue with can add another list to another one as a clone like new i want to know is how can i add a list into another one without any reference of the wirecoords new coord new i 0 i lt i as soon the list change it also change inside can i fix this\n"
     ]
    }
   ],
   "source": [
    "int_to_word = {value: key for key, value in int_mapping.items()}\n",
    "class_labels = {0: \"csharp\",\n",
    "                1: \"java\",\n",
    "                2: \"javascript\",\n",
    "                3: \"python\"}\n",
    "\n",
    "inputs = ''\n",
    "\n",
    "for query in train_set[0][\"text\"]:\n",
    "    if query != 0:\n",
    "        inputs += f\" {int_to_word[int(query)]}\"\n",
    "\n",
    "print(inputs)\n",
    "#label = class_labels[train_set[0][\"label\"]]\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "    \n",
    "def save_plots(train_accuracy, validation_accuracy, train_loss, validation_loss):\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize = (12, 10))\n",
    "    plt.plot(train_accuracy, color = 'black', label = 'training accuracy')\n",
    "    plt.plot(validation_accuracy, color = 'blue', label = 'validation accuracy')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"../output/accuracy.png\")\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.figure(figsize = (12, 10))\n",
    "    plt.plot(train_loss, color = 'black', label = 'training loss')\n",
    "    plt.plot(validation_loss, color = 'blue', label = 'validation loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"../output/loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4)\n",
    "\n",
    "validation_loader = DataLoader(validation_set,\n",
    "                               batch_size = batch_size,\n",
    "                               shuffle = False,\n",
    "                               num_workers = 4)\n",
    "\n",
    "test_loader = DataLoader(test_set,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = False,\n",
    "                         num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def multi_accuracy(labels, outputs):\\n    outputs = torch.argmax(outputs, dim = 1)\\n    running_correct = torch.eq(outputs, labels)\\n    accuracy = torch.mean(running_correct.float())\\n    return accuracy'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def multi_accuracy(labels, outputs):\n",
    "    outputs = torch.argmax(outputs, dim = 1)\n",
    "    running_correct = torch.eq(outputs, labels)\n",
    "    accuracy = torch.mean(running_correct.float())\n",
    "    return accuracy\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print(\"Training...\")\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for i, data in tqdm(enumerate(trainloader), total = len(trainloader)):\n",
    "        counter += 1\n",
    "        inputs, labels = data[\"text\"], data[\"label\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels, dtype = torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward prop\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.squeeze(outputs, -1)\n",
    "        \n",
    "        # Calculating loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        # Calculating accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (prediction == labels).sum().item()\n",
    "        \n",
    "        # Backward prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_accuracy = 100 * (train_running_correct / len(trainloader.dataset))\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    print('Validation...')\n",
    "    validation_running_loss = 0.0\n",
    "    validation_running_correct = 0\n",
    "    counter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total = len(testloader)):\n",
    "            counter += 1\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = torch.tensor(labels, dtype = torch.float32).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward prop\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.squeeze(outputs, -1)\n",
    "            \n",
    "            # Calculating loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            validation_running_loss += loss.item()\n",
    "            \n",
    "            # Calculating accuracy\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            validation_running_correct += (prediction == labels).sum().item()\n",
    "            \n",
    "    epoch_loss = validation_running_loss / counter\n",
    "    epoch_accuracy = 100 * (validation_running_correct / len(testloader.dataset))\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, embed_dim):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim = embed_dim)\n",
    "        self.linear1 = nn.Linear(max_len, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        bs, _, _ = x.shape\n",
    "        x = Func.adaptive_avg_pool1d(x, 1).reshape(bs, -1)\n",
    "        out = self.linear1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingModel(\n",
      "  (embedding): Embedding(187861, 50)\n",
      "  (linear1): Linear(in_features=2256, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = EmbeddingModel(len(int_mapping) + 1,\n",
    "                       MAX_LEN,\n",
    "                       EMBED_DIM).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,395,307 parameters.\n",
      "9,395,307 training parameters.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "total_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_parameters:,} parameters.\")\n",
    "trainable_parameters = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{trainable_parameters:,} training parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n",
      "Learning rate: 0.0001\n",
      "Epochs: 35\n",
      "\n",
      "Epoch 1 of 35\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learning_rate = 0.0001\n",
    "print(f\"Running on: {device}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Epochs: {epochs}\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "    train_loss_per_epoch, train_accuracy_per_epoch = train(model,\n",
    "                                                               train_loader,\n",
    "                                                               optimizer,\n",
    "                                                               criterion)\n",
    "    val_loss_per_epoch, val_accuracy_per_epoch = validate(model,\n",
    "                                                              validation_loader,\n",
    "                                                              criterion)\n",
    "    train_loss.append(train_loss_per_epoch)\n",
    "    validation_loss.append(val_loss_per_epoch)\n",
    "    train_accuracy.append(train_accuracy_per_epoch)\n",
    "    validation_accuracy.append(val_accuracy_per_epoch)\n",
    "    print(f\"Training loss: {train_loss_per_epoch:.3f}, Training accuracy: {train_accuracy_per_epoch:.3f}\")\n",
    "    print(f\"Validation loss: {val_loss_per_epoch:.3f}, Validation accuracy: {val_accuracy_per_epoch:.3f}\")\n",
    "    print(\"~ \" * 100)\n",
    "    \n",
    "    torch.save(\n",
    "        model, os.path.join(output_dir, 'model.pth')\n",
    "    )    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(output_dir, 'model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = validate(model,\n",
    "                                    test_loader,\n",
    "                                    criterion)\n",
    "\n",
    "print(f\"Test accuracy:{test_accuracy}, Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_vector(int_mapping, text):\n",
    "    corpus = [word for word in text.split()]\n",
    "    int_vector = [int_mapping[word] for word in text.split() if word in int_mapping]\n",
    "    return int_vector\n",
    "\n",
    "def pad_features(int_vector, max_len):\n",
    "    features = np.zeros((1, max_len), dtype = int)\n",
    "    if len(int_vector) <= max_len:\n",
    "        zeros = list(np.zeros)(max_len - len(int_vector))\n",
    "        new = zeros + int_vector\n",
    "    else:\n",
    "        new = int_vector[:max_len]\n",
    "    features = np.array(new)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct the last part to predict for multiclas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
